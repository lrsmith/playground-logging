input {
  file {
    path => "/logs/elb"
    start_position => "beginning"
    sincedb_path => "/dev/null"
  }
}


filter {

  # Mask password
  mutate {
    gsub => [ "[message]", "(password=)([^&\s\"]+)", "\1*********" ]
  }

  # Drop successful health check messages
  if [message] =~ /(\d*\.?\d* ){3}200 \d+ \d+ \d+ "\S+ \S+ \S+" "ELB-HealthChecker/ {
    drop { }
  }


  # Clone the log for parsing into Splunk Format
  clone {
    clones => ['splunk']
  }

  # Parse clone for sending it to Splunk using evetn collector.
  if [type] == 'splunk' {

    # Set the type to a metadata field which does not get passed as part of message
    mutate { add_field => { "[@metadata][type]" => "%{type}" } }

    # Set the index field based on the load-balancer
    grok {
      match => [ "message", " app/%{NOTSPACE:index}/" ]
    }

    # Hardcode the sourcetype to ALB access logs
    mutate {
      add_field => { "sourcetype" => "aws:alb:accesslogs" }
    }

    # Rename the message into an HEC event field
    mutate {
      rename => { "message" => "event" }
    }

    # Remove non HEC compliant fields
    mutate {
      remove_field => [ "type","message", "path","@version","@timestamp"  ]
    }

  # For the original message, parse into JSON fields
  } else {
     grok {
       match => ["message","%{TIMESTAMP_ISO8601:timestamp} %{NOTSPACE:loadbalancer} %{IP:client_ip}:%{NUMBER:client_port:int} (?:%{IP:backend_ip}:%{NUMBER:backend_port:int}|-) %{NUMBER:request_processing_time:float} %{NUMBER:backend_processing_time:float} %{NUMBER:response_processing_time:float} (?:%{NUMBER:elb_status_code:int}|-) (?:%{NUMBER:backend_status_code:int}|-) %{NUMBER:received_bytes:int} %{NUMBER:sent_bytes:int} \"(?:%{WORD:verb}|-) (?:%{GREEDYDATA:request}|-) (?:HTTP/%{NUMBER:httpversion}|-( )?)%{SPACE}\" \"%{DATA:userAgent|-}\"( %{NOTSPACE:ssl_cipher|-} %{NOTSPACE:ssl_protocol}|-) (%{NOTSPACE:target_group_arn})? (\"%{NOTSPACE:trace_id}\")? (\"%{NOTSPACE:RequestDomain}\")? (?:\"%{NOTSPACE:chosen_cert_arn}\"|-)? (?:%{NUMBER:matched_rule_priority:int}|-) (%{TIMESTAMP_ISO8601:request_creation_time})? (?:\"%{NOTSPACE:action_executed}\"|-)? (?:\"%{GREEDYDATA:redirect_url}\"|-)? (?:\"%{GREEDYDATA:error_reason}\"|-)?"]        
     }
     grok {
       match => [ "request", "%{URIPROTO:http_protocol}://(?:%{USER:user}(?::[^@]*)?@)?(?:%{URIHOST:domain_name})?(?:%{URIPATHPARAM:RequestPath})?" ]
     }
     if [request] != "-" {
       grok {
        match => ["request", "(?<request>[^?]*)"]
        overwrite => ["request"]
        }
    }
    if "?" in [RequestPath] {
      grok {
        match => ["RequestPath", "^(?<RequestPath>.*)\?.*$"]
        overwrite => ["RequestPath"]
        }
    }
    useragent {
      source => "userAgent"
    }
    date {
      match => ["timestamp", "ISO8601"]
    }
    geoip {
      source => "client_ip"
    }
    ruby { code => 'event.set("RequestTime", event.get("request_processing_time").to_f + event.get("response_processing_time").to_f + event.get("backend_processing_time").to_f)' 
    }
  } 
}

output {
    file {
        path => "/logs/elb.out"
    }

  # Based on meta-data field if its for splunk, send to splunk.
  if [@metadata][type] == 'splunk' {
    splunk {
      url => "http://splunk:8088/services/collector?auto_extract_timestamp=true"
      token => "7da8974a-d93d-4caa-b755-8757acb530e9"
      is_batch => true
    }
 # Otherwise it is for stdout 
 } else { 
  stdout {
    codec => rubydebug
  }
 }
}
